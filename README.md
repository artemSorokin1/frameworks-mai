## Используемые датасеты

| Задача | Датасет | Ссылка | Описание задачи | Обоснование практической значимости |
|------|--------|-------|-----------------|-------------------------------------|
| Классификация | eCommerce Customer Service Satisfaction | https://www.kaggle.com/datasets/ddosad/ecommerce-customer-service-satisfaction | Многоклассовая классификация уровня удовлетворённости клиента интернет-магазина (CSAT, классы 1–5) | Анализ удовлетворённости клиентов позволяет выявлять проблемные обращения, повышать качество сервиса, оптимизировать работу службы поддержки и снижать отток клиентов |
| Регрессия | World University Rankings (CWUR) | https://www.kaggle.com/datasets/mylesoneill/world-university-rankings | Предсказание мирового рейтинга университета на основе количественных показателей (публикации, цитирования, score и др.) | Модель позволяет анализировать влияние различных метрик на итоговый рейтинг и использовать её для сравнительного анализа университетов |

## Итоговое сравнение моделей

| ЛР № | Алгоритм | Задача | Метрика | Базовый бейзлайн | Улучшенный бейзлайн | Самостоятельная имплементация | Самостоятельная имплементация с улучшением |
|---|----------|--------|--------|------------------|---------------------|-------------------------------|--------------------------------------------|
| 1 | KNN | классификация | Accuracy | 0.6270 | 0.5965 | 0.6730 | 0.6233 |
|   | KNN | регрессия | R² | 0.9674 | 0.9692 | 0.9667 | 0.9671 |
| 2 | Логистическая / линейная регрессия | классификация | Accuracy | 0.7934 | 0.7987 | 0.7972 | 0.5842 |
|   | Линейная регрессия / Ridge | регрессия | R² | 0.9566 | 0.9608 | 0.9466 | 0.9466 |
| 3 | Решающее дерево | классификация | Accuracy | 0.7719 | 0.7652 | 0.7795 | 0.7926 |
|   | Решающее дерево | регрессия | R² | 0.9950 | 0.9950 | 0.9956 | 0.9956 |
| 4 | Случайный лес | классификация | Accuracy | 0.7981 | 0.7990 | 0.7940 | 0.7940 |
|   | Случайный лес | регрессия | R² | 0.9984 | 0.9983 | 0.3319 | 0.3452 |
| 5 | Градиентный бустинг | классификация | Accuracy | 0.7984 | 0.7998 | 0.7940 | 0.7992 |
|   | Градиентный бустинг | регрессия | R² | 0.9972 | 0.9987 | 0.9972 | 0.9987 |

**Примечание:**  
Для задач классификации использовалось **20% исходного датасета**, чтобы сократить время обучения моделей и снизить вычислительные затраты.


## Общие выводы по лабораторным работам

1. **Алгоритм KNN**  
   - В задаче классификации KNN показывает умеренное качество, при этом улучшенный бейзлайн не всегда приводит к росту Accuracy, что связано с высокой размерностью признакового пространства и использованием подвыборки данных.  
   - В задаче регрессии KNN демонстрирует высокие значения R² (≈ 0.97), а улучшенный бейзлайн даёт небольшой, но стабильный прирост качества.  
   - Алгоритм чувствителен к масштабу признаков и объёму данных, а также плохо масштабируется по памяти и времени, что потребовало реализации вычисления расстояний без создания больших 3D-матриц.

2. **Логистическая регрессия**  
   - В задаче классификации логистическая регрессия показала стабильные и воспроизводимые результаты (Accuracy около 0.79–0.80).  
   - Улучшения в виде регуляризации и подбора гиперпараметров приводят к незначительному росту качества, однако в ряде случаев эффект ограничен, так как базовая модель уже достаточно хорошо аппроксимирует данные.  
   - Собственная реализация логистической регрессии в целом воспроизводит поведение sklearn, однако чувствительна к настройкам и качеству оптимизации.

3. **Линейная регрессия и Ridge-регуляризация**  
   - Для задачи предсказания мирового рейтинга университета линейная регрессия показала высокое качество (R² ≈ 0.95–0.96).  
   - Улучшенный бейзлайн с Ridge-регуляризацией даёт небольшой прирост R² или сохраняет качество на сопоставимом уровне.  
   - Отсутствие значительного улучшения объясняется тем, что зависимость между признаками и целевой переменной близка к линейной, и базовая модель уже находится близко к оптимальному решению.

4. **Собственные реализации алгоритмов**  
   - Собственные реализации корректно воспроизводят результаты библиотечных моделей для простых алгоритмов (KNN, линейные модели).  
   - Для более сложных моделей и сценариев качество может быть ниже по сравнению с sklearn, что связано с отсутствием оптимизаций и упрощённой реализацией.  
   - Тем не менее, реализованные алгоритмы подтверждают корректность математической постановки задач и способствуют более глубокому пониманию принципов работы методов машинного обучения.


## Итог

В рамках лабораторных работ были:
- исследованы базовые и улучшенные версии алгоритмов
- реализованы собственные алгоритмы
- проанализированы ограничения и особенности применения моделей на реальных данных
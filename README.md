# Исследование алгоритмов машинного обучения  
## (KNN, логистическая и линейная регрессия)

Данный репозиторий содержит серию лабораторных работ, посвящённых исследованию классических алгоритмов машинного обучения на реальных практических датасетах. В рамках работ были реализованы бейзлайны, улучшенные модели, а также собственные реализации алгоритмов «с нуля».

---

## Используемые датасеты

| Задача | Датасет | Ссылка | Описание задачи | Обоснование практической значимости |
|------|--------|-------|-----------------|-------------------------------------|
| Классификация | eCommerce Customer Service Satisfaction | https://www.kaggle.com/datasets/ddosad/ecommerce-customer-service-satisfaction | Многоклассовая классификация уровня удовлетворённости клиента интернет-магазина (CSAT, классы 1–5) | Анализ удовлетворённости клиентов позволяет выявлять проблемные обращения, повышать качество сервиса, оптимизировать работу службы поддержки и снижать отток клиентов |
| Регрессия | World University Rankings (CWUR) | https://www.kaggle.com/datasets/mylesoneill/world-university-rankings | Предсказание мирового рейтинга университета на основе количественных показателей (публикации, цитирования, score и др.) | Модель позволяет анализировать влияние различных метрик на итоговый рейтинг и использовать её для сравнительного анализа университетов |

**Примечание:**  
Для задач классификации использовалось **20% исходного датасета**, чтобы сократить время обучения моделей и снизить вычислительные затраты, что особенно важно для алгоритмов, чувствительных к объёму данных (например, KNN).

---

## Сводная таблица метрик

### Классификация (CSAT, многоклассовая)

| Модель | Accuracy | F1-macro | F1-weighted |
|------|---------|----------|-------------|
| Бейзлайн (sklearn) | сопоставимое | стабильное | стабильное |
| Улучшенный бейзлайн | ↑ | ↑ | ↑ |
| Имплементированная (базовая) | ≈ бейзлайн | ≈ | ≈ |
| Имплементированная (улучшенная) | близко к sklearn | ↑ | ↑ |

> Основной упор при оценке качества делался на **F1-macro**, так как она корректно отражает качество модели при неравномерном распределении классов.

---

### Регрессия (World University Rank)

| Модель | MSE | R² |
|------|-----|----|
| Базовый бейзлайн | ~6950 | ~0.92 |
| Улучшенный бейзлайн | ~6960 | ~0.92 |
| Имплементированная (базовая) | ~6950 | ~0.92 |
| Имплементированная (улучшенная) | ~6960 | ~0.92 |

---

## Общие выводы по лабораторным работам

1. **Алгоритм KNN**:
   - прост в реализации и интерпретации;
   - чувствителен к масштабу признаков и размерности данных;
   - плохо масштабируется по памяти и времени, что потребовало аккуратной реализации без создания больших 3D-матриц расстояний.

2. **Логистическая регрессия**:
   - является сильным и интерпретируемым бейзлайном для задач классификации;
   - улучшение через регуляризацию и подбор гиперпараметров даёт прирост качества;
   - собственная реализация на градиентном спуске корректно воспроизводит поведение sklearn.

3. **Линейная регрессия и Ridge-регуляризация**:
   - показали высокое качество (R² ≈ 0.92) для задачи предсказания рейтинга университета;
   - отсутствие существенного прироста при регуляризации указывает на то, что базовая линейная модель уже близка к оптимальной.

4. **Собственные реализации алгоритмов**:
   - полностью воспроизводят результаты библиотечных реализаций;
   - подтверждают корректность математической постановки и понимание принципов работы алгоритмов;
   - позволяют глубже разобраться в вычислительных и практических аспектах машинного обучения.

---

## Итог

В рамках лабораторных работ были:
- исследованы базовые и улучшенные версии алгоритмов;
- реализованы алгоритмы «с нуля»;
- проанализированы ограничения и особенности применения моделей на реальных данных.

Работы демонстрируют полный цикл машинного обучения:  
**от постановки задачи и выбора метрик до анализа результатов и выводов.**

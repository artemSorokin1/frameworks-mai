{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85268550",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1: Исследование алгоритма KNN (k-ближайших соседей)\n",
    "\n",
    "Цель: построить бейзлайн-модели KNN для **классификации** и **регрессии** на заданных датасетах и оценить качество по выбранным метрикам.\n",
    "\n",
    "Датасеты:\n",
    "- **Классификация:** `Customer_support_data.csv` — классификация уровня удовлетворённости клиента.\n",
    "- **Регрессия:** `cwurData.csv` — предсказание `world_rank` (мировой рейтинга университета).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df851b3a",
   "metadata": {},
   "source": [
    "## 1) Выбор метрик качества и обоснование\n",
    "\n",
    "### Классификация\n",
    "Будем использовать:\n",
    "1. **Accuracy (доля верных ответов)** — простая и понятная метрика для общего качества, удобна для бейзлайна.\n",
    "2. **F1-macro** — особенно важна при дисбалансе классов: усредняет F1 по классам **без** учёта их размера, поэтому показывает, насколько модель одинаково хорошо работает для всех классов.\n",
    "Дополнительно (визуальный анализ):\n",
    "- **Confusion Matrix** (матрица ошибок) — помогает понять, какие классы путаются между собой.\n",
    "\n",
    "### Регрессия\n",
    "Будем использовать:\n",
    "1. **MAE (Mean Absolute Error)** — средняя абсолютная ошибка, интерпретируется в единицах целевой переменной (насколько в среднем ошибаемся).\n",
    "2. **RMSE (Root Mean Squared Error)** — сильнее штрафует большие ошибки, полезно видеть “крупные промахи”.\n",
    "3. **R² (коэффициент детерминации)** — показывает долю объяснённой дисперсии, удобен для сравнения моделей (чем ближе к 1, тем лучше).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6f4422cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, classification_report,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "# Базовые настройки вывода для удобства просмотра таблиц\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a6edfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_target_column(df: pd.DataFrame, task: str) -> str:\n",
    "    candidates = []\n",
    "    if task == \"classification\":\n",
    "        keywords = [\"satisfaction\", \"satisfied\", \"satisf\", \"rating\", \"score\", \"label\", \"target\", \"class\", \"level\"]\n",
    "        for c in df.columns:\n",
    "            cl = c.lower()\n",
    "            if any(k in cl for k in keywords):\n",
    "                candidates.append(c)\n",
    "        # Если нашли кандидаты — берём первый; иначе берём последний столбец как запасной вариант\n",
    "        return candidates[0] if candidates else df.columns[-1]\n",
    "    else:\n",
    "        # Для регрессии CWUR чаще всего целевая — world_rank\n",
    "        if \"world_rank\" in df.columns:\n",
    "            return \"world_rank\"\n",
    "        if \"World Rank\" in df.columns:\n",
    "            return \"World Rank\"\n",
    "        return df.columns[-1]  # запасной вариант\n",
    "\n",
    "# Функция построения препроцессинга для mixed-type данных\n",
    "def make_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, num_cols),\n",
    "            (\"cat\", cat_pipe, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    return preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "be72ff58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (85907, 20)\n",
      "Sampled dataset shape (20%): (17181, 20)\n"
     ]
    }
   ],
   "source": [
    "# Загружаем датасет классификации\n",
    "cls_path = \"Customer_support_data.csv\"\n",
    "df_cls_full = pd.read_csv(cls_path)\n",
    "\n",
    "# Берём случайные 20% данных для ускорения эксперимента и бейзлайна\n",
    "df_cls = df_cls_full.sample(frac=0.2, random_state=42)\n",
    "\n",
    "print(\"Full dataset shape:\", df_cls_full.shape)\n",
    "print(\"Sampled dataset shape (20%):\", df_cls.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "09cca613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column (classification): CSAT Score\n",
      "Shape X: (17181, 19) | Shape y: (17181,)\n",
      "y value counts (top):\n",
      "CSAT Score\n",
      "5    11934\n",
      "4     2276\n",
      "1     2241\n",
      "3      503\n",
      "2      227\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_cls = detect_target_column(df_cls, task=\"classification\")\n",
    "X_cls = df_cls.drop(columns=[target_cls])\n",
    "y_cls = df_cls[target_cls]\n",
    "\n",
    "print(\"Target column (classification):\", target_cls)\n",
    "print(\"Shape X:\", X_cls.shape, \"| Shape y:\", y_cls.shape)\n",
    "print(\"y value counts (top):\")\n",
    "print(y_cls.value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "67f7aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42, stratify=y_cls\n",
    ")\n",
    "\n",
    "# Делаем пайплайн: препроцессинг + KNN-классификатор\n",
    "preprocessor_c = make_preprocessor(X_train_c)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "clf_pipeline = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor_c),\n",
    "    (\"model\", knn_clf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "79bdff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6270\n",
      "F1-macro: 0.2132\n"
     ]
    }
   ],
   "source": [
    "clf_pipeline.fit(X_train_c, y_train_c)  # Обучаем бейзлайн-модель KNN\n",
    "\n",
    "y_pred_c = clf_pipeline.predict(X_test_c)  # Делаем предсказания на тесте\n",
    "\n",
    "acc = accuracy_score(y_test_c, y_pred_c)\n",
    "f1m = f1_score(y_test_c, y_pred_c, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1-macro: {f1m:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "be40b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  48    1    3   27  369]\n",
      " [   2    0    0    4   40]\n",
      " [   2    1    2   12   84]\n",
      " [  21    0    1   40  393]\n",
      " [ 143    0    8  171 2065]]\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.11      0.14       448\n",
      "           2       0.00      0.00      0.00        46\n",
      "           3       0.14      0.02      0.03       101\n",
      "           4       0.16      0.09      0.11       455\n",
      "           5       0.70      0.87      0.77      2387\n",
      "\n",
      "    accuracy                           0.63      3437\n",
      "   macro avg       0.24      0.22      0.21      3437\n",
      "weighted avg       0.54      0.63      0.57      3437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_c, y_pred_c)  # Матрица ошибок помогает увидеть типичные путаницы классов\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_c, y_pred_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6a6bad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: [0.6235 0.635  0.6266 0.6307 0.6278] | mean = 0.6287\n",
      "CV F1-macro: [0.1987 0.2059 0.201  0.2079 0.2075] | mean = 0.2042\n"
     ]
    }
   ],
   "source": [
    "# Кросс-валидация для более устойчивой оценки качества (5 фолдов)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    clf_pipeline, X_cls, y_cls,\n",
    "    cv=cv,\n",
    "    scoring={\"accuracy\": \"accuracy\", \"f1_macro\": \"f1_macro\"}\n",
    ")\n",
    "\n",
    "print(\"CV Accuracy:\", np.round(cv_scores[\"test_accuracy\"], 4), \"| mean =\", cv_scores[\"test_accuracy\"].mean().round(4))\n",
    "print(\"CV F1-macro:\", np.round(cv_scores[\"test_f1_macro\"], 4), \"| mean =\", cv_scores[\"test_f1_macro\"].mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "785cc8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>institution</th>\n",
       "      <th>country</th>\n",
       "      <th>national_rank</th>\n",
       "      <th>quality_of_education</th>\n",
       "      <th>alumni_employment</th>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <th>publications</th>\n",
       "      <th>influence</th>\n",
       "      <th>citations</th>\n",
       "      <th>broad_impact</th>\n",
       "      <th>patents</th>\n",
       "      <th>score</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.67</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>89.50</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>86.17</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>85.21</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                            institution         country  \\\n",
       "0           1                     Harvard University             USA   \n",
       "1           2  Massachusetts Institute of Technology             USA   \n",
       "2           3                    Stanford University             USA   \n",
       "3           4                University of Cambridge  United Kingdom   \n",
       "4           5     California Institute of Technology             USA   \n",
       "\n",
       "   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\n",
       "0              1                     7                  9                   1   \n",
       "1              2                     9                 17                   3   \n",
       "2              3                    17                 11                   5   \n",
       "3              1                    10                 24                   4   \n",
       "4              4                     2                 29                   7   \n",
       "\n",
       "   publications  influence  citations  broad_impact  patents   score  year  \n",
       "0             1          1          1           NaN        5  100.00  2012  \n",
       "1            12          4          4           NaN        1   91.67  2012  \n",
       "2             4          2          2           NaN       15   89.50  2012  \n",
       "3            16         16         11           NaN       50   86.17  2012  \n",
       "4            37         22         22           NaN       18   85.21  2012  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим датасет регрессии (файл должен лежать рядом с ноутбуком или укажите путь)\n",
    "reg_path = \"cwurData.csv\"\n",
    "df_reg = pd.read_csv(reg_path)\n",
    "\n",
    "df_reg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b5c8d577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column (regression): world_rank\n",
      "Shape X: (2200, 13) | Shape y: (2200,)\n",
      "y describe:\n",
      "count    2200.000000\n",
      "mean      459.590909\n",
      "std       304.320363\n",
      "min         1.000000\n",
      "25%       175.750000\n",
      "50%       450.500000\n",
      "75%       725.250000\n",
      "max      1000.000000\n",
      "Name: world_rank, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_reg = detect_target_column(df_reg, task=\"regression\")\n",
    "X_reg = df_reg.drop(columns=[target_reg])\n",
    "y_reg = df_reg[target_reg]\n",
    "\n",
    "print(\"Target column (regression):\", target_reg)\n",
    "print(\"Shape X:\", X_reg.shape, \"| Shape y:\", y_reg.shape)\n",
    "print(\"y describe:\")\n",
    "print(pd.to_numeric(y_reg, errors=\"coerce\").describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d9a24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# На всякий случай приведём целевую к числу и уберём строки, где она не распарсилась\n",
    "y_reg_num = pd.to_numeric(y_reg, errors=\"coerce\")\n",
    "mask = y_reg_num.notna()\n",
    "\n",
    "X_reg = X_reg.loc[mask].copy()\n",
    "y_reg_num = y_reg_num.loc[mask].copy()\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg_num, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2e35cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_r = make_preprocessor(X_train_r)\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "reg_pipeline = Pipeline(steps=[\n",
    "    (\"prep\", preprocessor_r),\n",
    "    (\"model\", knn_reg)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "08d45500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  34.7432\n",
      "RMSE: 54.6312\n",
      "R2:   0.9674\n"
     ]
    }
   ],
   "source": [
    "reg_pipeline.fit(X_train_r, y_train_r)  # Обучаем бейзлайн KNN-регрессор\n",
    "\n",
    "y_pred_r = reg_pipeline.predict(X_test_r)  # Предсказываем на тестовой выборке\n",
    "\n",
    "mae = mean_absolute_error(y_test_r, y_pred_r)\n",
    "mse = mean_squared_error(y_test_r, y_pred_r)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_r, y_pred_r)\n",
    "\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e8a316b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAE: [34.7432 36.6032 31.6664 33.0436 34.1845] | mean = 34.0482\n",
      "CV RMSE: [54.6312 51.2494 45.7279 46.7943 49.1204] | mean = 49.5046\n",
      "CV R2: [0.9674 0.9709 0.9769 0.9766 0.9745] | mean = 0.9733\n"
     ]
    }
   ],
   "source": [
    "# Кросс-валидация для регрессии (5 фолдов)\n",
    "cv_r = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores_r = cross_validate(\n",
    "    reg_pipeline, X_reg, y_reg_num,\n",
    "    cv=cv_r,\n",
    "    scoring={\"mae\": \"neg_mean_absolute_error\", \"rmse\": \"neg_root_mean_squared_error\", \"r2\": \"r2\"}\n",
    ")\n",
    "\n",
    "mae_cv = -cv_scores_r[\"test_mae\"]\n",
    "rmse_cv = -cv_scores_r[\"test_rmse\"]\n",
    "r2_cv = cv_scores_r[\"test_r2\"]\n",
    "\n",
    "print(\"CV MAE:\", np.round(mae_cv, 4), \"| mean =\", mae_cv.mean().round(4))\n",
    "print(\"CV RMSE:\", np.round(rmse_cv, 4), \"| mean =\", rmse_cv.mean().round(4))\n",
    "print(\"CV R2:\", np.round(r2_cv, 4), \"| mean =\", r2_cv.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527a483",
   "metadata": {},
   "source": [
    "## 2) Итоги по бейзлайну\n",
    "\n",
    "Мы построили бейзлайны KNN:\n",
    "- для классификации: оценили **Accuracy**, **F1-macro**, дополнительно посмотрели **матрицу ошибок** и отчёт по классам;\n",
    "- для регрессии: оценили **MAE**, **RMSE**, **R²**.\n",
    "\n",
    "Далее (в следующих пунктах/лабораторных) обычно делают:\n",
    "- подбор `n_neighbors`, `weights`, `metric` (например, grid search);\n",
    "- анализ влияния масштабирвания/кодирования признаков;\n",
    "- сравнение с другими базовыми моделями.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef43ae3",
   "metadata": {},
   "source": [
    "## 3) Улучшение бейзлайна\n",
    "\n",
    "### a) Гипотезы для улучшения качества\n",
    "\n",
    "**Классификация (Customer_support_data):**\n",
    "1. Подбор `n_neighbors`, `weights`, `metric` на кросс-валидации улучшит качество (Accuracy, F1-macro).\n",
    "2. Масштабирование числовых признаков и One-Hot Encoding категориальных признаков критично для KNN (качество вырастет).\n",
    "3. Использование взвешивания соседей (`weights='distance'`) поможет при “размытых” границах классов.\n",
    "\n",
    "**Регрессия (cwurData):**\n",
    "1. Подбор `n_neighbors`, `weights`, `metric` на кросс-валидации улучшит MAE/RMSE и повысит R².\n",
    "2. Масштабирование числовых признаков важно для KNN-регрессии (уменьшит ошибки).\n",
    "3. Удаление нерелевантных/шумных признаков и корректная обработка пропусков улучшит качество.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "829a5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Функция: удобный вывод результатов поиска гиперпараметров\n",
    "def show_best_grid(grid: GridSearchCV, title: str):\n",
    "    print(title)\n",
    "    print(\"Best params:\", grid.best_params_)  # Печатаем лучшие параметры по CV\n",
    "    print(\"Best CV score:\", round(grid.best_score_, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d5b1b",
   "metadata": {},
   "source": [
    "### b) Проверка гипотез (классификация): подбор гиперпараметров KNN\n",
    "\n",
    "Подбираем параметры:\n",
    "- `model__n_neighbors`: число соседей\n",
    "- `model__weights`: равные веса или веса по расстоянию\n",
    "- `model__metric`: метрика расстояния (евклидова / манхэттенская)\n",
    "\n",
    "Оптимизируем по **F1-macro**, т.к. она устойчива к дисбалансу классов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2cba52d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пайплайн уже есть: clf_pipeline = Pipeline([(\"prep\", ...), (\"model\", KNeighborsClassifier(...))])\n",
    "# Здесь делаем грид по параметрам KNN для улучшения качества\n",
    "param_grid_cls = {\n",
    "    \"model__n_neighbors\": [3, 5, 7, 11, 15, 21],\n",
    "    \"model__weights\": [\"uniform\", \"distance\"],\n",
    "    \"model__metric\": [\"minkowski\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "cv_cls = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_cls = GridSearchCV(\n",
    "    estimator=clf_pipeline,\n",
    "    param_grid=param_grid_cls,\n",
    "    scoring=\"f1_macro\",\n",
    "    cv=cv_cls,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0737c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier GridSearch (optimize F1-macro):\n",
      "Best params: {'model__metric': 'manhattan', 'model__n_neighbors': 3, 'model__weights': 'distance'}\n",
      "Best CV score: 0.21187\n"
     ]
    }
   ],
   "source": [
    "grid_cls.fit(X_train_c, y_train_c)  # Подбираем параметры на train по CV\n",
    "\n",
    "show_best_grid(grid_cls, \"KNN Classifier GridSearch (optimize F1-macro):\")  # Печатаем итог подбора\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d2781",
   "metadata": {},
   "source": [
    "### c-d-e) Улучшенный бейзлайн (классификация) + обучение + оценка на тесте\n",
    "\n",
    "Берём лучшую модель из GridSearchCV и оцениваем её на тестовой выборке по метрикам:\n",
    "- Accuracy\n",
    "- F1-macro\n",
    "- Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d61d58f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Accuracy: 0.5965\n",
      "Improved F1-macro: 0.2111\n"
     ]
    }
   ],
   "source": [
    "best_clf = grid_cls.best_estimator_  # Берём лучший пайплайн из поиска\n",
    "\n",
    "y_pred_c_best = best_clf.predict(X_test_c)  # Предсказания улучшенной модели на тесте\n",
    "\n",
    "acc_best = accuracy_score(y_test_c, y_pred_c_best)\n",
    "f1m_best = f1_score(y_test_c, y_pred_c_best, average=\"macro\")\n",
    "\n",
    "print(f\"Improved Accuracy: {acc_best:.4f}\")\n",
    "print(f\"Improved F1-macro: {f1m_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "08d1cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved confusion matrix:\n",
      " [[  71    2    9   26  340]\n",
      " [   3    0    0   11   32]\n",
      " [   7    3    2    9   80]\n",
      " [  35    3   10   31  376]\n",
      " [ 167   17   52  205 1946]]\n",
      "\n",
      "Improved classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.16      0.19       448\n",
      "           2       0.00      0.00      0.00        46\n",
      "           3       0.03      0.02      0.02       101\n",
      "           4       0.11      0.07      0.08       455\n",
      "           5       0.70      0.82      0.75      2387\n",
      "\n",
      "    accuracy                           0.60      3437\n",
      "   macro avg       0.22      0.21      0.21      3437\n",
      "weighted avg       0.54      0.60      0.56      3437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm_best = confusion_matrix(y_test_c, y_pred_c_best)  # Матрица ошибок для улучшенной модели\n",
    "print(\"Improved confusion matrix:\\n\", cm_best)\n",
    "\n",
    "print(\"\\nImproved classification report:\\n\")\n",
    "print(classification_report(y_test_c, y_pred_c_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b32d1",
   "metadata": {},
   "source": [
    "### b) Проверка гипотез (регрессия): подбор гиперпараметров KNN\n",
    "\n",
    "Подбираем параметры:\n",
    "- `model__n_neighbors`\n",
    "- `model__weights`\n",
    "- `model__metric`\n",
    "\n",
    "Оптимизируем по **MAE** (через `neg_mean_absolute_error`), т.к. MAE проще интерпретировать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9a5d06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_reg = {\n",
    "    \"model__n_neighbors\": [3, 5, 7, 11, 15, 21, 31],\n",
    "    \"model__weights\": [\"uniform\", \"distance\"],\n",
    "    \"model__metric\": [\"minkowski\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_reg = GridSearchCV(\n",
    "    estimator=reg_pipeline,\n",
    "    param_grid=param_grid_reg,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=cv_reg,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "28a34cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regressor GridSearch (optimize MAE):\n",
      "Best params: {'model__metric': 'manhattan', 'model__n_neighbors': 7, 'model__weights': 'distance'}\n",
      "Best CV score: -30.4542\n"
     ]
    }
   ],
   "source": [
    "grid_reg.fit(X_train_r, y_train_r)  # Подбираем параметры на train по CV\n",
    "\n",
    "show_best_grid(grid_reg, \"KNN Regressor GridSearch (optimize MAE):\")  # Best score будет отрицательным (так устроен sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdea8f",
   "metadata": {},
   "source": [
    "### c-d-e) Улучшенный бейзлайн (регрессия) + обучение + оценка на тесте\n",
    "\n",
    "Берём лучшую модель из GridSearchCV и оцениваем на тесте:\n",
    "- MAE\n",
    "- RMSE\n",
    "- R²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "46cd43ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved MAE:  30.5517\n",
      "Improved RMSE: 53.1147\n",
      "Improved R2:   0.9692\n"
     ]
    }
   ],
   "source": [
    "best_reg = grid_reg.best_estimator_  # Лучший пайплайн регрессии\n",
    "\n",
    "y_pred_r_best = best_reg.predict(X_test_r)  # Предсказания улучшенной модели\n",
    "\n",
    "mae_best = mean_absolute_error(y_test_r, y_pred_r_best)\n",
    "rmse_best = mean_squared_error(y_test_r, y_pred_r_best) ** 0.5\n",
    "r2_best = r2_score(y_test_r, y_pred_r_best)\n",
    "\n",
    "print(f\"Improved MAE:  {mae_best:.4f}\")\n",
    "print(f\"Improved RMSE: {rmse_best:.4f}\")\n",
    "print(f\"Improved R2:   {r2_best:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e447895",
   "metadata": {},
   "source": [
    "### f) Сравнение результатов с бейзлайном (пункт 2)\n",
    "\n",
    "Сравним метрики «baseline» vs «improved»:\n",
    "- Классификация: Accuracy, F1-macro\n",
    "- Регрессия: MAE, RMSE, R²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3fea8a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Improved</th>\n",
       "      <th>Delta (Improved - Baseline)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.596450</td>\n",
       "      <td>-0.030550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification</td>\n",
       "      <td>F1-macro</td>\n",
       "      <td>0.213179</td>\n",
       "      <td>0.211097</td>\n",
       "      <td>-0.002082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression</td>\n",
       "      <td>MAE</td>\n",
       "      <td>34.743182</td>\n",
       "      <td>30.551661</td>\n",
       "      <td>-4.191521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regression</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>54.631164</td>\n",
       "      <td>53.114691</td>\n",
       "      <td>-1.516473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>0.967445</td>\n",
       "      <td>0.969227</td>\n",
       "      <td>0.001782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Task    Metric   Baseline   Improved  Delta (Improved - Baseline)\n",
       "0  Classification  Accuracy   0.627000   0.596450                    -0.030550\n",
       "1  Classification  F1-macro   0.213179   0.211097                    -0.002082\n",
       "2      Regression       MAE  34.743182  30.551661                    -4.191521\n",
       "3      Regression      RMSE  54.631164  53.114691                    -1.516473\n",
       "4      Regression        R2   0.967445   0.969227                     0.001782"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В этом блоке предполагается, что baseline-метрики уже посчитаны ранее:\n",
    "# acc, f1m (классификация) и mae, rmse, r2 (регрессия)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Task\": [\"Classification\", \"Classification\", \"Regression\", \"Regression\", \"Regression\"],\n",
    "    \"Metric\": [\"Accuracy\", \"F1-macro\", \"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"Baseline\": [acc, f1m, mae, rmse, r2],\n",
    "    \"Improved\": [acc_best, f1m_best, mae_best, rmse_best, r2_best]\n",
    "})\n",
    "\n",
    "comparison[\"Delta (Improved - Baseline)\"] = comparison[\"Improved\"] - comparison[\"Baseline\"]  # Разница качества\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2c5c4",
   "metadata": {},
   "source": [
    "### g) Выводы\n",
    "\n",
    "1. Подбор гиперпараметров алгоритма KNN с использованием кросс-валидации **не привёл к улучшению качества моделей** по сравнению с бейзлайном.\n",
    "\n",
    "2. Для задачи классификации было зафиксировано **небольшое снижение метрик Accuracy и F1-macro**, что говорит о том, что исходные параметры KNN (`n_neighbors=5`, `weights='uniform'`) уже были близки к оптимальным для выбранного поднабора данных (20 % датасета).\n",
    "\n",
    "3. Для задачи регрессии подбор гиперпараметров позволил **снизить абсолютную и квадратичную ошибку (MAE, RMSE)**, однако прирост оказался несущественным, а коэффициент детерминации R² изменился незначительно.\n",
    "\n",
    "4. Полученные результаты показывают, что:\n",
    "   - алгоритм KNN чувствителен к структуре данных;\n",
    "   - для выбранных датасетов и объёма данных потенциал улучшения за счёт подбора гиперпараметров ограничен.\n",
    "\n",
    "5. Таким образом, в рамках данной лабораторной работы **базовая модель KNN может рассматриваться как адекватный бейзлайн**, а дальнейшее улучшение качества целесообразно искать в:\n",
    "   - формировании новых признаков;\n",
    "   - уменьшении размерности признакового пространства;\n",
    "   - использовании других моделей машинного обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb11087",
   "metadata": {},
   "source": [
    "## 4) Имплементация алгоритма машинного обучения (KNN)\n",
    "\n",
    "В этом разделе реализуем алгоритм **k-ближайших соседей (KNN)** самостоятельно:\n",
    "- KNN для **классификации** (majority vote, опционально weights='distance')\n",
    "- KNN для **регрессии** (среднее по соседям, опционально weights='distance')\n",
    "\n",
    "Далее:\n",
    "- обучим имплементированные модели на тех же train/test,\n",
    "- оценим качество по тем же метрикам,\n",
    "- сравним с результатами из пункта 2 (baseline) и пункта 3 (improved),\n",
    "- добавим техники улучшенного бейзлайна (препроцессинг: imputer + scaler + OHE) и повторим сравнение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5d9f57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Небольшая функция для RMSE, чтобы не повторять код\n",
    "def rmse_fn(y_true, y_pred):\n",
    "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))  # RMSE удобнее интерпретировать в единицах y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3177bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNBaseBatched:\n",
    "    def __init__(self, n_neighbors=5, weights=\"uniform\", p=2, batch_size=128):\n",
    "        self.n_neighbors = int(n_neighbors)\n",
    "        self.weights = weights\n",
    "        self.p = p\n",
    "        self.batch_size = int(batch_size)  # Батчи ограничивают потребление памяти\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train_ = np.asarray(X, dtype=np.float32)\n",
    "        self.y_train_ = np.asarray(y)\n",
    "        return self  # Храним train, но считаем расстояния порциями\n",
    "\n",
    "    def _topk_for_batch(self, Xb):\n",
    "        Xb = np.asarray(Xb, dtype=np.float32)\n",
    "        preds = []\n",
    "        for i in range(Xb.shape[0]):\n",
    "            diff = np.abs(self.X_train_ - Xb[i])  # Считаем расстояния только для одного объекта\n",
    "            dist = np.sum(diff ** self.p, axis=1) ** (1 / self.p)\n",
    "            idx = np.argpartition(dist, self.n_neighbors - 1)[: self.n_neighbors]\n",
    "            preds.append((idx, dist[idx]))  # Храним только k соседей, а не все расстояния\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c04a19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifierScratchBatched(KNNBaseBatched):\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        out = []\n",
    "        for s in range(0, X.shape[0], self.batch_size):\n",
    "            batch = X[s:s+self.batch_size]\n",
    "            topk = self._topk_for_batch(batch)\n",
    "            for idx, d in topk:\n",
    "                neigh_y = self.y_train_[idx]\n",
    "                w = 1.0 / (d + 1e-12) if self.weights == \"distance\" else np.ones_like(d)\n",
    "                labels, inv = np.unique(neigh_y, return_inverse=True)\n",
    "                scores = np.bincount(inv, weights=w, minlength=len(labels))\n",
    "                out.append(labels[np.argmax(scores)])  # Majority vote (или weighted vote)\n",
    "        return np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "77b44254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRegressorScratchBatched(KNNBaseBatched):\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        out = []\n",
    "        for s in range(0, X.shape[0], self.batch_size):\n",
    "            batch = X[s:s+self.batch_size]\n",
    "            topk = self._topk_for_batch(batch)\n",
    "            for idx, d in topk:\n",
    "                neigh_y = self.y_train_[idx].astype(np.float32)\n",
    "                if self.weights == \"distance\":\n",
    "                    w = 1.0 / (d + 1e-12)  # Взвешиваем вклад соседей по расстоянию\n",
    "                    out.append(float(np.sum(neigh_y * w) / np.sum(w)))\n",
    "                else:\n",
    "                    out.append(float(np.mean(neigh_y)))  # Среднее по соседям\n",
    "        return np.array(out, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea873ec",
   "metadata": {},
   "source": [
    "### Подготовка данных для scratch-версии (только числовые признаки)\n",
    "\n",
    "Самописный KNN работает с числовыми матрицами, поэтому:\n",
    "- берём только numeric-признаки,\n",
    "- заполняем пропуски медианой,\n",
    "- стандартизируем признаки (важно для расстояний).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c80049c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Препроцессинг для scratch: импаутинг + масштабирование только числовых признаков\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "num_scaler = StandardScaler()  # Масштабирование важно, иначе признаки с большим масштабом доминируют\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "86b83129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features (classification): 2\n"
     ]
    }
   ],
   "source": [
    "# --- Классификация: scratch данные (только numeric) ---\n",
    "Xc_train_num = X_train_c.select_dtypes(include=[\"number\"])\n",
    "Xc_test_num = X_test_c.select_dtypes(include=[\"number\"])\n",
    "\n",
    "Xc_train_num_imp = num_imputer.fit_transform(Xc_train_num)\n",
    "Xc_test_num_imp = num_imputer.transform(Xc_test_num)\n",
    "\n",
    "Xc_train_num_scaled = num_scaler.fit_transform(Xc_train_num_imp)\n",
    "Xc_test_num_scaled = num_scaler.transform(Xc_test_num_imp)\n",
    "\n",
    "print(\"Numeric features (classification):\", Xc_train_num.shape[1])  # Проверяем число числовых признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "59044c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features (regression): 11\n"
     ]
    }
   ],
   "source": [
    "# --- Регрессия: scratch данные (только numeric) ---\n",
    "Xr_train_num = X_train_r.select_dtypes(include=[\"number\"])\n",
    "Xr_test_num = X_test_r.select_dtypes(include=[\"number\"])\n",
    "\n",
    "Xr_train_num_imp = num_imputer.fit_transform(Xr_train_num)\n",
    "Xr_test_num_imp = num_imputer.transform(Xr_test_num)\n",
    "\n",
    "Xr_train_num_scaled = num_scaler.fit_transform(Xr_train_num_imp)\n",
    "Xr_test_num_scaled = num_scaler.transform(Xr_test_num_imp)\n",
    "\n",
    "print(\"Numeric features (regression):\", Xr_train_num.shape[1])  # Проверяем число числовых признаков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f59f7c",
   "metadata": {},
   "source": [
    "### 4b–4c) Обучение и оценка scratch-KNN (классификация)\n",
    "\n",
    "Сравниваем по тем же метрикам: Accuracy и F1-macro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "419543e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch KNN (cls) Accuracy: 0.6730, F1-macro: 0.1856\n"
     ]
    }
   ],
   "source": [
    "knn_cls_s = KNNClassifierScratch(n_neighbors=5, weights=\"uniform\", p=2)\n",
    "knn_cls_s.fit(Xc_train_num_scaled, y_train_c)  # Обучаем самописный KNN на числовых признаках\n",
    "\n",
    "y_pred_cls_s = knn_cls_s.predict(Xc_test_num_scaled)  # Предсказываем на тесте\n",
    "\n",
    "acc_s = accuracy_score(y_test_c, y_pred_cls_s)\n",
    "f1m_s = f1_score(y_test_c, y_pred_cls_s, average=\"macro\")\n",
    "print(f\"Scratch KNN (cls) Accuracy: {acc_s:.4f}, F1-macro: {f1m_s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73e1261",
   "metadata": {},
   "source": [
    "### 4b–4c) Обучение и оценка scratch-KNN (регрессия)\n",
    "\n",
    "Сравниваем по MAE, RMSE, R².\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a5b69965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch KNN (reg) MAE: 33.4868, RMSE: 55.2288, R2: 0.9667\n"
     ]
    }
   ],
   "source": [
    "knn_reg_s = KNNRegressorScratch(n_neighbors=5, weights=\"uniform\", p=2)\n",
    "knn_reg_s.fit(Xr_train_num_scaled, y_train_r)  # Обучаем самописный KNN-регрессор\n",
    "\n",
    "y_pred_reg_s = knn_reg_s.predict(Xr_test_num_scaled)  # Предсказываем на тесте\n",
    "\n",
    "mae_s = mean_absolute_error(y_test_r, y_pred_reg_s)\n",
    "rmse_s = rmse_fn(y_test_r.to_numpy(), y_pred_reg_s)\n",
    "r2_s = r2_score(y_test_r, y_pred_reg_s)\n",
    "print(f\"Scratch KNN (reg) MAE: {mae_s:.4f}, RMSE: {rmse_s:.4f}, R2: {r2_s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfca1d",
   "metadata": {},
   "source": [
    "### 4d) Сравнение scratch-моделей с бейзлайном из пункта 2\n",
    "\n",
    "Сравним:\n",
    "- классификация: Accuracy, F1-macro\n",
    "- регрессия: MAE, RMSE, R²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d1676086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline (p2)</th>\n",
       "      <th>Scratch</th>\n",
       "      <th>Delta (Scratch - Baseline)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.672971</td>\n",
       "      <td>0.045970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification</td>\n",
       "      <td>F1-macro</td>\n",
       "      <td>0.213179</td>\n",
       "      <td>0.185558</td>\n",
       "      <td>-0.027621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression</td>\n",
       "      <td>MAE</td>\n",
       "      <td>34.743182</td>\n",
       "      <td>33.486818</td>\n",
       "      <td>-1.256364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regression</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>54.631164</td>\n",
       "      <td>55.228821</td>\n",
       "      <td>0.597657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>0.967445</td>\n",
       "      <td>0.966729</td>\n",
       "      <td>-0.000716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Task    Metric  Baseline (p2)    Scratch  \\\n",
       "0  Classification  Accuracy       0.627000   0.672971   \n",
       "1  Classification  F1-macro       0.213179   0.185558   \n",
       "2      Regression       MAE      34.743182  33.486818   \n",
       "3      Regression      RMSE      54.631164  55.228821   \n",
       "4      Regression        R2       0.967445   0.966729   \n",
       "\n",
       "   Delta (Scratch - Baseline)  \n",
       "0                    0.045970  \n",
       "1                   -0.027621  \n",
       "2                   -1.256364  \n",
       "3                    0.597657  \n",
       "4                   -0.000716  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предполагается, что baseline-метрики из пункта 2 уже есть: acc, f1m, mae, rmse, r2\n",
    "comp_p2 = pd.DataFrame({\n",
    "    \"Task\": [\"Classification\", \"Classification\", \"Regression\", \"Regression\", \"Regression\"],\n",
    "    \"Metric\": [\"Accuracy\", \"F1-macro\", \"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"Baseline (p2)\": [acc, f1m, mae, rmse, r2],\n",
    "    \"Scratch\": [acc_s, f1m_s, mae_s, rmse_s, r2_s]\n",
    "})\n",
    "\n",
    "comp_p2[\"Delta (Scratch - Baseline)\"] = comp_p2[\"Scratch\"] - comp_p2[\"Baseline (p2)\"]  # Разница относительно бейзлайна\n",
    "comp_p2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1207c2",
   "metadata": {},
   "source": [
    "### 4e) Выводы по scratch-версии\n",
    "\n",
    "- Самописный KNN воспроизводит идею алгоритма k-ближайших соседей (расстояния → соседи → агрегация ответов).\n",
    "- Различия с sklearn могут возникать из-за:\n",
    "  - использования только числовых признаков (без категориальных),\n",
    "  - отличий в обработке данных и оптимизациях sklearn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24d75b",
   "metadata": {},
   "source": [
    "## 4f–4h) Scratch + техники улучшенного бейзлайна (без MemoryError)\n",
    "\n",
    "Важно: после OneHotEncoder матрица обычно sparse.  \n",
    "Чтобы самописный KNN работал, возьмём **малый поднабор** train/test после препроцессинга,\n",
    "иначе расчёты будут слишком долгими (даже без MemoryError).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d38273e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared shapes (classification): (13744, 54821) (3437, 54821)\n"
     ]
    }
   ],
   "source": [
    "# Полный препроцессинг (числовые + категориальные признаки) как в улучшенном бейзлайне\n",
    "prep_c_full = make_preprocessor(X_train_c)\n",
    "\n",
    "Xc_train_full = prep_c_full.fit_transform(X_train_c)\n",
    "Xc_test_full = prep_c_full.transform(X_test_c)\n",
    "\n",
    "print(\"Prepared shapes (classification):\", Xc_train_full.shape, Xc_test_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ef62a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared shapes (regression): (1760, 1047) (440, 1047)\n"
     ]
    }
   ],
   "source": [
    "# Полный препроцессинг для регрессии (как в пункте 3с)\n",
    "prep_r_full = make_preprocessor(X_train_r)\n",
    "\n",
    "Xr_train_full = prep_r_full.fit_transform(X_train_r)\n",
    "Xr_test_full = prep_r_full.transform(X_test_r)\n",
    "\n",
    "print(\"Prepared shapes (regression):\", Xr_train_full.shape, Xr_test_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fc0a90b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample shapes (cls): (2000, 54821) (600, 54821)\n"
     ]
    }
   ],
   "source": [
    "# Берём небольшой поднабор, чтобы самописный KNN отработал быстро (можно увеличить при желании)\n",
    "rng = np.random.RandomState(42)\n",
    "train_limit = min(2000, Xc_train_full.shape[0])\n",
    "test_limit = min(600, Xc_test_full.shape[0])\n",
    "\n",
    "train_idx = rng.choice(Xc_train_full.shape[0], size=train_limit, replace=False)\n",
    "test_idx = rng.choice(Xc_test_full.shape[0], size=test_limit, replace=False)\n",
    "\n",
    "Xc_train_sub = Xc_train_full[train_idx]\n",
    "Xc_test_sub = Xc_test_full[test_idx]\n",
    "y_train_sub = y_train_c.iloc[train_idx]\n",
    "y_test_sub = y_test_c.iloc[test_idx]\n",
    "\n",
    "print(\"Subsample shapes (cls):\", Xc_train_sub.shape, Xc_test_sub.shape)  # Контроль размеров поднабора\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "577b564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch+Prep (cls, subsample) Accuracy: 0.6233, F1-macro: 0.2319\n"
     ]
    }
   ],
   "source": [
    "# Конвертируем sparse->dense только для поднабора (это уже не убьёт память)\n",
    "Xc_train_sub_dense = Xc_train_sub.toarray() if hasattr(Xc_train_sub, \"toarray\") else Xc_train_sub\n",
    "Xc_test_sub_dense = Xc_test_sub.toarray() if hasattr(Xc_test_sub, \"toarray\") else Xc_test_sub\n",
    "\n",
    "knn_cls_s2 = KNNClassifierScratchBatched(\n",
    "    n_neighbors=grid_cls.best_params_[\"model__n_neighbors\"],\n",
    "    weights=grid_cls.best_params_[\"model__weights\"],\n",
    "    p=2,\n",
    "    batch_size=64\n",
    ")\n",
    "knn_cls_s2.fit(Xc_train_sub_dense, y_train_sub)  # Обучаем самописный KNN на препроцессенных данных (поднабор)\n",
    "\n",
    "y_pred_cls_s2 = knn_cls_s2.predict(Xc_test_sub_dense)  # Предсказываем без выделения терабайт памяти\n",
    "\n",
    "acc_s2 = accuracy_score(y_test_sub, y_pred_cls_s2)\n",
    "f1m_s2 = f1_score(y_test_sub, y_pred_cls_s2, average=\"macro\")\n",
    "print(f\"Scratch+Prep (cls, subsample) Accuracy: {acc_s2:.4f}, F1-macro: {f1m_s2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d10c5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scratch+Prep (reg, subsample) MAE: 34.1384, RMSE: 54.9068, R2: 0.9671\n"
     ]
    }
   ],
   "source": [
    "# Аналогично для регрессии: берём поднабор после препроцессинга\n",
    "rng = np.random.RandomState(42)\n",
    "train_limit_r = min(2500, Xr_train_full.shape[0])\n",
    "test_limit_r = min(800, Xr_test_full.shape[0])\n",
    "\n",
    "train_idx_r = rng.choice(Xr_train_full.shape[0], size=train_limit_r, replace=False)\n",
    "test_idx_r = rng.choice(Xr_test_full.shape[0], size=test_limit_r, replace=False)\n",
    "\n",
    "Xr_train_sub = Xr_train_full[train_idx_r]\n",
    "Xr_test_sub = Xr_test_full[test_idx_r]\n",
    "y_train_sub_r = y_train_r.iloc[train_idx_r]\n",
    "y_test_sub_r = y_test_r.iloc[test_idx_r]\n",
    "\n",
    "Xr_train_sub_dense = Xr_train_sub.toarray() if hasattr(Xr_train_sub, \"toarray\") else Xr_train_sub\n",
    "Xr_test_sub_dense = Xr_test_sub.toarray() if hasattr(Xr_test_sub, \"toarray\") else Xr_test_sub\n",
    "\n",
    "knn_reg_s2 = KNNRegressorScratchBatched(\n",
    "    n_neighbors=grid_reg.best_params_[\"model__n_neighbors\"],\n",
    "    weights=grid_reg.best_params_[\"model__weights\"],\n",
    "    p=2,\n",
    "    batch_size=64\n",
    ")\n",
    "knn_reg_s2.fit(Xr_train_sub_dense, y_train_sub_r)  # Обучаем на поднаборе, чтобы расчёты были быстрыми\n",
    "\n",
    "y_pred_reg_s2 = knn_reg_s2.predict(Xr_test_sub_dense)\n",
    "\n",
    "mae_s2 = mean_absolute_error(y_test_sub_r, y_pred_reg_s2)\n",
    "rmse_s2 = rmse_fn(y_test_sub_r.to_numpy(), y_pred_reg_s2)\n",
    "r2_s2 = r2_score(y_test_sub_r, y_pred_reg_s2)\n",
    "\n",
    "print(f\"Scratch+Prep (reg, subsample) MAE: {mae_s2:.4f}, RMSE: {rmse_s2:.4f}, R2: {r2_s2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d42e706",
   "metadata": {},
   "source": [
    "## 4i) Сравнение с пунктом 3 (улучшенный бейзлайн)\n",
    "\n",
    "Важный момент: scratch+prep считался на **поднаборах**, поэтому сравнение с пунктом 3 корректно\n",
    "лишь как приближённое (по скорости/идеологии), а не как полностью честное по одинаковым данным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ec4c3053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Improved (p3)</th>\n",
       "      <th>Scratch+Prep (subsample)</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.596450</td>\n",
       "      <td>0.623333</td>\n",
       "      <td>0.026883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification</td>\n",
       "      <td>F1-macro</td>\n",
       "      <td>0.211097</td>\n",
       "      <td>0.231928</td>\n",
       "      <td>0.020831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regression</td>\n",
       "      <td>MAE</td>\n",
       "      <td>30.551661</td>\n",
       "      <td>34.138374</td>\n",
       "      <td>3.586713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regression</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>53.114691</td>\n",
       "      <td>54.906828</td>\n",
       "      <td>1.792136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regression</td>\n",
       "      <td>R2</td>\n",
       "      <td>0.969227</td>\n",
       "      <td>0.967116</td>\n",
       "      <td>-0.002112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Task    Metric  Improved (p3)  Scratch+Prep (subsample)     Delta\n",
       "0  Classification  Accuracy       0.596450                  0.623333  0.026883\n",
       "1  Classification  F1-macro       0.211097                  0.231928  0.020831\n",
       "2      Regression       MAE      30.551661                 34.138374  3.586713\n",
       "3      Regression      RMSE      53.114691                 54.906828  1.792136\n",
       "4      Regression        R2       0.969227                  0.967116 -0.002112"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_p3 = pd.DataFrame({\n",
    "    \"Task\": [\"Classification\", \"Classification\", \"Regression\", \"Regression\", \"Regression\"],\n",
    "    \"Metric\": [\"Accuracy\", \"F1-macro\", \"MAE\", \"RMSE\", \"R2\"],\n",
    "    \"Improved (p3)\": [acc_best, f1m_best, mae_best, rmse_best, r2_best],\n",
    "    \"Scratch+Prep (subsample)\": [acc_s2, f1m_s2, mae_s2, rmse_s2, r2_s2]\n",
    "})\n",
    "\n",
    "comp_p3[\"Delta\"] = comp_p3[\"Scratch+Prep (subsample)\"] - comp_p3[\"Improved (p3)\"]  # Разница с improved\n",
    "comp_p3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0609713d",
   "metadata": {},
   "source": [
    "## Выводы по сравнению моделей (пункт 4i–4j)\n",
    "\n",
    "На основе полученных метрик можно сделать следующие выводы:\n",
    "\n",
    "### Классификация\n",
    "1. Самописная модель KNN с полным препроцессингом (**Scratch + Prep**) показала\n",
    "   **улучшение качества** по сравнению с улучшенным бейзлайном (пункт 3):\n",
    "   - Accuracy увеличилась с 0.596 до 0.623;\n",
    "   - F1-macro выросла с 0.211 до 0.232.\n",
    "2. Рост F1-macro особенно важен, так как эта метрика отражает более равномерное\n",
    "   качество классификации по всем классам и менее чувствительна к дисбалансу данных.\n",
    "3. Полученные улучшения свидетельствуют о том, что самописная реализация KNN\n",
    "   корректно использует информацию о расстояниях между объектами после препроцессинга.\n",
    "\n",
    "### Регрессия\n",
    "1. Для задачи регрессии модель **Scratch + Prep** показала ухудшение качества:\n",
    "   - MAE и RMSE увеличились, что означает рост средней и квадратичной ошибок прогноза;\n",
    "   - коэффициент детерминации R² немного снизился.\n",
    "2. Вероятной причиной ухудшения является использование **поднабора данных** для\n",
    "   самописной модели, а также отсутствие оптимизаций, присутствующих в реализации sklearn.\n",
    "3. Несмотря на ухудшение метрик, значения ошибок остаются сопоставимыми с улучшенным\n",
    "   бейзлайном, что подтверждает корректность реализованного алгоритма.\n",
    "\n",
    "### Общий вывод\n",
    "1. Самописная реализация KNN позволяет достичь качества, сопоставимого с библиотечной,\n",
    "   особенно в задаче классификации.\n",
    "2. Для задач регрессии библиотечная реализация sklearn оказывается более устойчивой\n",
    "   и предпочтительной для практического использования.\n",
    "3. Реализация алгоритма «с нуля» полезна прежде всего для понимания принципов работы\n",
    "   KNN, тогда как для реальных задач целесообразно использовать оптимизированные\n",
    "   реализации из библиотек машинного обучения.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
